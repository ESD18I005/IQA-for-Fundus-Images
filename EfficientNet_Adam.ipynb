{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26145,"status":"ok","timestamp":1683363034140,"user":{"displayName":"ESD18I005 BOLLA MOUNIKA","userId":"03631579374868004325"},"user_tz":-330},"id":"vhtuSsiQyNFS","outputId":"0d387c19-ce15-497b-9316-4d566394e0e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZdfDAkbkyNIs","executionInfo":{"status":"ok","timestamp":1683363048433,"user_tz":-330,"elapsed":4361,"user":{"displayName":"ESD18I005 BOLLA MOUNIKA","userId":"03631579374868004325"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import backend as K\n","import keras\n","from keras.models import Sequential, Model,load_model\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","from google.colab.patches import cv2_imshow\n","from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n","from keras.preprocessing import image\n","from keras.initializers import glorot_uniform\n","from keras.applications import EfficientNetB0\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_riPpPKTxmzq","executionInfo":{"status":"ok","timestamp":1683363048434,"user_tz":-330,"elapsed":14,"user":{"displayName":"ESD18I005 BOLLA MOUNIKA","userId":"03631579374868004325"}}},"outputs":[],"source":["# train -> train0+train1+train2\n","train_path=\"/content/gdrive/MyDrive/TRAIN_UP\"\n","# test -> test0+test1+test2\n","test_path=\"/content/gdrive/MyDrive/TEST_UP\"\n","class_names=os.listdir(train_path)\n","class_names_test=os.listdir(test_path)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6tSSl6zx7XPW","executionInfo":{"status":"ok","timestamp":1683363048434,"user_tz":-330,"elapsed":13,"user":{"displayName":"ESD18I005 BOLLA MOUNIKA","userId":"03631579374868004325"}}},"outputs":[],"source":["train_datagen = ImageDataGenerator(zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15)\n","test_datagen = ImageDataGenerator(zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3580,"status":"ok","timestamp":1683363052001,"user":{"displayName":"ESD18I005 BOLLA MOUNIKA","userId":"03631579374868004325"},"user_tz":-330},"id":"3O_EhpHmxm73","outputId":"acfeafa9-7ea5-4c35-fb72-277c35fda805"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1392 images belonging to 3 classes.\n","Found 602 images belonging to 3 classes.\n"]}],"source":["train_generator = train_datagen.flow_from_directory(\"/content/gdrive/My Drive/TRAIN_UP\")\n","test_generator = test_datagen.flow_from_directory(\"/content/gdrive/My Drive/TEST_UP\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCh2Y-ZZxlL8","outputId":"790e7d28-3065-4726-c929-22bbef065728"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n","16705208/16705208 [==============================] - 1s 0us/step\n","Found 1392 images belonging to 3 classes.\n","Found 602 images belonging to 3 classes.\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","87/87 [==============================] - 1107s 13s/step - loss: 0.6857 - accuracy: 0.7019 - val_loss: 0.5578 - val_accuracy: 0.7458\n","Epoch 2/40\n","87/87 [==============================] - 274s 3s/step - loss: 0.5092 - accuracy: 0.7945 - val_loss: 0.4937 - val_accuracy: 0.7907\n","Epoch 3/40\n","87/87 [==============================] - 273s 3s/step - loss: 0.4577 - accuracy: 0.8103 - val_loss: 0.4867 - val_accuracy: 0.7890\n","Epoch 4/40\n","87/87 [==============================] - 271s 3s/step - loss: 0.4248 - accuracy: 0.8247 - val_loss: 0.4463 - val_accuracy: 0.8007\n","Epoch 5/40\n","87/87 [==============================] - 270s 3s/step - loss: 0.4054 - accuracy: 0.8326 - val_loss: 0.4470 - val_accuracy: 0.7990\n","Epoch 6/40\n","87/87 [==============================] - 269s 3s/step - loss: 0.3953 - accuracy: 0.8391 - val_loss: 0.4418 - val_accuracy: 0.7990\n","Epoch 7/40\n","87/87 [==============================] - 262s 3s/step - loss: 0.3907 - accuracy: 0.8499 - val_loss: 0.4580 - val_accuracy: 0.8040\n","Epoch 8/40\n","87/87 [==============================] - 251s 3s/step - loss: 0.3666 - accuracy: 0.8463 - val_loss: 0.4120 - val_accuracy: 0.8289\n","Epoch 9/40\n","87/87 [==============================] - 252s 3s/step - loss: 0.3522 - accuracy: 0.8506 - val_loss: 0.4501 - val_accuracy: 0.8106\n","Epoch 10/40\n","87/87 [==============================] - 250s 3s/step - loss: 0.3410 - accuracy: 0.8599 - val_loss: 0.4165 - val_accuracy: 0.8223\n","Epoch 11/40\n","87/87 [==============================] - 249s 3s/step - loss: 0.3435 - accuracy: 0.8671 - val_loss: 0.4470 - val_accuracy: 0.8123\n","Epoch 12/40\n","87/87 [==============================] - 250s 3s/step - loss: 0.3421 - accuracy: 0.8678 - val_loss: 0.4357 - val_accuracy: 0.8223\n","Epoch 13/40\n","87/87 [==============================] - 249s 3s/step - loss: 0.3445 - accuracy: 0.8549 - val_loss: 0.4307 - val_accuracy: 0.8206\n","Epoch 14/40\n","87/87 [==============================] - 249s 3s/step - loss: 0.3068 - accuracy: 0.8764 - val_loss: 0.4130 - val_accuracy: 0.8106\n","Epoch 15/40\n","87/87 [==============================] - 251s 3s/step - loss: 0.3102 - accuracy: 0.8800 - val_loss: 0.4113 - val_accuracy: 0.8256\n","Epoch 16/40\n","87/87 [==============================] - 255s 3s/step - loss: 0.3070 - accuracy: 0.8764 - val_loss: 0.4133 - val_accuracy: 0.8306\n","Epoch 17/40\n","87/87 [==============================] - 265s 3s/step - loss: 0.2936 - accuracy: 0.8807 - val_loss: 0.4088 - val_accuracy: 0.8289\n","Epoch 18/40\n","87/87 [==============================] - 264s 3s/step - loss: 0.2966 - accuracy: 0.8779 - val_loss: 0.4303 - val_accuracy: 0.8206\n","Epoch 19/40\n","87/87 [==============================] - 259s 3s/step - loss: 0.2897 - accuracy: 0.8793 - val_loss: 0.4371 - val_accuracy: 0.8040\n","Epoch 20/40\n","87/87 [==============================] - 260s 3s/step - loss: 0.2848 - accuracy: 0.8886 - val_loss: 0.4341 - val_accuracy: 0.8106\n","Epoch 21/40\n","87/87 [==============================] - 261s 3s/step - loss: 0.2666 - accuracy: 0.8937 - val_loss: 0.4115 - val_accuracy: 0.8156\n","Epoch 22/40\n","87/87 [==============================] - 261s 3s/step - loss: 0.2875 - accuracy: 0.8851 - val_loss: 0.4611 - val_accuracy: 0.7791\n","Epoch 23/40\n","87/87 [==============================] - 258s 3s/step - loss: 0.2696 - accuracy: 0.8858 - val_loss: 0.3830 - val_accuracy: 0.8239\n","Epoch 24/40\n","87/87 [==============================] - 258s 3s/step - loss: 0.2691 - accuracy: 0.8930 - val_loss: 0.4180 - val_accuracy: 0.8256\n","Epoch 25/40\n","87/87 [==============================] - 257s 3s/step - loss: 0.2658 - accuracy: 0.8937 - val_loss: 0.4068 - val_accuracy: 0.8256\n","Epoch 26/40\n","87/87 [==============================] - 257s 3s/step - loss: 0.2482 - accuracy: 0.9016 - val_loss: 0.4029 - val_accuracy: 0.8339\n","Epoch 27/40\n","87/87 [==============================] - 256s 3s/step - loss: 0.2482 - accuracy: 0.9045 - val_loss: 0.4205 - val_accuracy: 0.8140\n","Epoch 28/40\n","87/87 [==============================] - 253s 3s/step - loss: 0.2448 - accuracy: 0.9009 - val_loss: 0.4134 - val_accuracy: 0.8289\n","Epoch 29/40\n","87/87 [==============================] - 254s 3s/step - loss: 0.2769 - accuracy: 0.8872 - val_loss: 0.4088 - val_accuracy: 0.8239\n","Epoch 30/40\n","87/87 [==============================] - 255s 3s/step - loss: 0.2419 - accuracy: 0.9052 - val_loss: 0.4109 - val_accuracy: 0.8206\n","Epoch 31/40\n","87/87 [==============================] - 256s 3s/step - loss: 0.2396 - accuracy: 0.9066 - val_loss: 0.4180 - val_accuracy: 0.8189\n","Epoch 32/40\n","87/87 [==============================] - 256s 3s/step - loss: 0.2286 - accuracy: 0.9131 - val_loss: 0.3852 - val_accuracy: 0.8355\n","Epoch 33/40\n","87/87 [==============================] - 256s 3s/step - loss: 0.2384 - accuracy: 0.9023 - val_loss: 0.4203 - val_accuracy: 0.8090\n","Epoch 34/40\n","87/87 [==============================] - 258s 3s/step - loss: 0.2412 - accuracy: 0.8951 - val_loss: 0.4041 - val_accuracy: 0.8189\n","Epoch 35/40\n","87/87 [==============================] - 253s 3s/step - loss: 0.2361 - accuracy: 0.9102 - val_loss: 0.4410 - val_accuracy: 0.8223\n","Epoch 36/40\n","87/87 [==============================] - 256s 3s/step - loss: 0.2398 - accuracy: 0.9059 - val_loss: 0.4087 - val_accuracy: 0.8355\n","Epoch 37/40\n","87/87 [==============================] - 256s 3s/step - loss: 0.2192 - accuracy: 0.9145 - val_loss: 0.4386 - val_accuracy: 0.8140\n","Epoch 38/40\n","87/87 [==============================] - 255s 3s/step - loss: 0.2228 - accuracy: 0.9131 - val_loss: 0.3858 - val_accuracy: 0.8488\n","Epoch 39/40\n","87/87 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.9159"]}],"source":["\n","import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","\n","# Load the pre-trained EfficientNet model without the top layer\n","base_model = EfficientNetB0(weights='imagenet', input_shape=(224, 224, 3),include_top=False)\n","\n","# Add a new top layer\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(1024, activation='relu')(x)\n","predictions = Dense(3, activation='softmax')(x)\n","\n","# Define the new model\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Freeze the pre-trained layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Compile the model\n","model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","train_generator = train_datagen.flow_from_directory(\n","    '/content/gdrive/My Drive/TRAIN_UP',\n","    target_size=(128, 128),\n","    batch_size=16,\n","    class_mode='categorical')\n","\n","test_generator = test_datagen.flow_from_directory(\n","    '/content/gdrive/My Drive/TEST_UP',\n","    target_size=(128, 128),\n","    batch_size=16,\n","    class_mode='categorical')\n","H = model.fit(train_generator,validation_data =test_generator, epochs=40,verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RP0gKNg4mZXL"},"outputs":[],"source":["model.evaluate_generator(test_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jh7VUal7nIBL"},"outputs":[],"source":["from keras.models import model_from_json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHj8LMj6hkX2"},"outputs":[],"source":["model.save_weights('/content/gdrive/My Drive/EN_Weights_UP.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VlSVvjUiCQU"},"outputs":[],"source":["mkdir -p saved_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_kSAHEa5ivuJ"},"outputs":[],"source":["model.save('saved_model/my_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsYZwxyWcLQl"},"outputs":[],"source":["# Saving model weights into drive\n","#model.save(\"/content/gdrive/My Drive/EN_Weights_UP.h5\")\n","import json\n","model_json = model.to_json()\n","with open(\"/content/gdrive/My Drive/EN.json\",\"w\") as json_file:\n","  json_file.write(str(model_json))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qDq_TfznQ4oG"},"outputs":[],"source":["import pandas as pd\n","hist_df = pd.DataFrame(H.history) \n","\n","# save to json:  \n","hist_json_file = 'history.json' \n","with open(hist_json_file, mode='w') as f:\n","    hist_df.to_json(f)\n","\n","# or save to csv: \n","hist_csv_file = 'history.csv'\n","with open(hist_csv_file, mode='w') as f:\n","    hist_df.to_csv(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vr_fKjw6b86R"},"outputs":[],"source":["mc = ModelCheckpoint('/content/gdrive/My Drive/EN.h5', monitor='val_accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Snsr7ImLK2T6"},"outputs":[],"source":["def predict_(image_path):\n","  #Load the Model from Json File\n","  json_file = open('/content/gdrive/My Drive/EN.json', 'r')\n","  model_json_c = json_file.read()\n","  json_file.close()\n","  model_c = model_from_json(model_json_c)\n","  #Load the weights\n","  model_c.load_weights(\"/content/gdrive/My Drive/EN.h5\")\n","  #Compile the model\n","  opt = SGD(lr=1e-4, momentum=0.9)\n","  model_c.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n","  #load the image you want to classify\n","  image = cv2.imread(image_path)\n","  image = cv2.resize(image, (224,224))\n","  cv2_imshow(image)\n","  #predict the image\n","  preds = model_c.predict(np.expand_dims(image, axis=0))[0]\n","  prediction = max(preds)\n","  print(preds)\n","\n","  if prediction==preds[0]:\n","      print(\"Predicted Label: 0\")\n","  elif prediction==preds[1]:\n","      print(\"Predicted Label: 1\")\n","  else:\n","      print(\"Predicted Label: 2\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mSMrOVu4XeHP"},"outputs":[],"source":["predict_(\"/content/gdrive/My Drive/TEST_UP/Test_img_0/17023_right.jpeg\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5F-xfAIYPQv"},"outputs":[],"source":["predict_(\"/content/gdrive/MyDrive/train.zip/train/28780_right.jpeg\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-iyP1PiBUl6"},"outputs":[],"source":["hist_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eNmQzcdL_6zU"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","loss_train = hist_df['loss']\n","loss_val = hist_df['val_loss']\n","epochs = range(40)\n","plt.plot(epochs, loss_train, 'g', label='Training loss')\n","plt.plot(epochs, loss_val, 'b', label='validation loss')\n","plt.title('Training and Validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1OwCfGB3_6-Q"},"outputs":[],"source":["loss_train = hist_df['accuracy']\n","loss_val = hist_df['val_accuracy']\n","epochs = range(40)\n","plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n","plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n","plt.title('Training and Validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LAqZeBwZDchi"},"outputs":[],"source":["true_value = []\n","predicted_value = []\n","plt.figure(figsize=(10,10))\n","import os\n","from os import listdir\n","# get the path or directory\n","testImages = []\n","folder_dir = \"/content/gdrive/MyDrive/test/DB0_test\"\n","for i in os.listdir(folder_dir):\n","    # check if the image ends with png or jpg or jpeg\n","    if (i.endswith(\".png\") or i.endswith(\".jpg\")\\\n","        or i.endswith(\".jpeg\")):\n","        testImages.append(folder_dir+'/'+i)\n","        true_value.append(0)\n","folder_dir = \"/content/gdrive/MyDrive/test/DB1_test\"\n","for i in os.listdir(folder_dir):\n","    # check if the image ends with png or jpg or jpeg\n","    if (i.endswith(\".png\") or i.endswith(\".jpg\")\\\n","        or i.endswith(\".jpeg\")):\n","        testImages.append(folder_dir+'/'+i)\n","        true_value.append(1)\n","folder_dir = \"/content/gdrive/MyDrive/test/DB2_test\"\n","for i in os.listdir(folder_dir):\n","    # check if the image ends with png or jpg or jpeg\n","    if (i.endswith(\".png\") or i.endswith(\".jpg\")\\\n","        or i.endswith(\".jpeg\")):\n","        testImages.append(folder_dir+'/'+i)\n","        true_value.append(2)\n","\n","\n","def predict_(image_path):\n","  #Load the Model from Json File\n","  json_file = open('/content/gdrive/My Drive/model.json', 'r')\n","  model_json_c = json_file.read()\n","  json_file.close()\n","  model_c = model_from_json(model_json_c)\n","  #Load the weights\n","  model_c.load_weights(\"/content/gdrive/My Drive/best_model.h5\")\n","  #Compile the model\n","  opt = SGD(lr=1e-4, momentum=0.9)\n","  model_c.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n","  #load the image you want to classify\n","  image = cv2.imread(image_path)\n","  image = cv2.resize(image, (224,224))\n","  #cv2_imshow(image)\n","  #predict the image\n","  preds = model_c.predict(np.expand_dims(image, axis=0))[0]\n","  prediction = max(preds)\n","  #print(preds)\n","\n","  if prediction==preds[0]:\n","      #print(\"Predicted Label: 0\")\n","      predicted_value.append(0)\n","  elif prediction==preds[1]:\n","      #print(\"Predicted Label: 1\")\n","      predicted_value.append(1)\n","  else:\n","      #print(\"Predicted Label: 2\")\n","      predicted_value.append(2)\n","\n","\n","for image in testImages:\n","  print(image)\n","  predict_(image)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQke_40JDcmY"},"outputs":[],"source":["li = []\n","for i in range(len(predicted_value)):\n","  li.append(i+1)\n","for i in range(len(predicted_value)):\n","  li[i] = li[i]+(predicted_value[i]-true_value[i])*10\n","Li = []\n","for i in range(i+1):\n","  Li.append(i+1)\n","\n","plt.figure(figsize=(20,20))\n","plt.scatter(Li, li, c =\"red\",\n","            linewidths =1,\n","            marker =\"*\",\n","            edgecolor =\"green\",\n","            s = 200)\n","plt.scatter(Li, Li, c =\"blue\",\n","            linewidths =0.11,\n","            marker =\".\",\n","            edgecolor =\"blue\",\n","            s = 20)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"me79ZqVJjTJg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1LUvPBzujTQ1"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1IuPSozuoH7ki_CS97FA_sn8GwKHJMhn3","timestamp":1683102725016}],"authorship_tag":"ABX9TyPIIzA72pIT7og9YdWJn3/2"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}